{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Python/2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import HTMLParser as htm\n",
    "import string\n",
    "import re\n",
    "\n",
    "# SK-learn library for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Positive</th>\n",
       "      <th>escape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138881940341260288:</td>\n",
       "      <td>I got a surprise for all you bitches...pull th...</td>\n",
       "      <td>:: surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>I got a surprise for all you bitches...pull th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144479819843911683:</td>\n",
       "      <td>If I was a thief.. The first thing I would ste...</td>\n",
       "      <td>:: joy</td>\n",
       "      <td>1</td>\n",
       "      <td>If I was a thief.. The first thing I would ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139110849120972800:</td>\n",
       "      <td>\"&amp;quot;@RevRunWisdom: not afraid of tomorrow, ...</td>\n",
       "      <td>:: fear</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"@RevRunWisdom: not afraid of tomorrow, for I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141532076791971840:</td>\n",
       "      <td>\"Extreme can neither fight nor fly.&amp;#xA;-- Wil...</td>\n",
       "      <td>:: fear</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Extreme can neither fight nor fly.\\n-- Willia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145353048817012736:</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "      <td>:: surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id                                              Tweet  \\\n",
       "0  138881940341260288:  I got a surprise for all you bitches...pull th...   \n",
       "1  144479819843911683:  If I was a thief.. The first thing I would ste...   \n",
       "2  139110849120972800:  \"&quot;@RevRunWisdom: not afraid of tomorrow, ...   \n",
       "3  141532076791971840:  \"Extreme can neither fight nor fly.&#xA;-- Wil...   \n",
       "4  145353048817012736:  Thinks that @melbahughes had a great 50th birt...   \n",
       "\n",
       "       Emotion  Positive                                             escape  \n",
       "0  :: surprise         0  I got a surprise for all you bitches...pull th...  \n",
       "1       :: joy         1  If I was a thief.. The first thing I would ste...  \n",
       "2      :: fear         0  \"\"@RevRunWisdom: not afraid of tomorrow, for I...  \n",
       "3      :: fear         0  \"Extreme can neither fight nor fly.\\n-- Willia...  \n",
       "4  :: surprise         0  Thinks that @melbahughes had a great 50th birt...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tweet_data_1.csv\",sep='\\t',quoting=3)\n",
    "data[\"escape\"] = data.apply(lambda row: htm.HTMLParser().unescape(row[1].decode(\"utf-8\")),axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':: joy' ':: joy' ':: fear' ..., ':: joy' ':: surprise' ':: sadness']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and test data frames\n",
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "\n",
    "# Train and test target labels\n",
    "train_pol_y = train.ix[:,3].tolist()\n",
    "test_pol_y = test.ix[:,3].tolist()\n",
    "\n",
    "#binarize emo labels\n",
    "from sklearn import preprocessing\n",
    "train_emo = train.ix[:,2].tolist()\n",
    "test_emo = test.ix[:,2].tolist()\n",
    "\n",
    "emo_bin = preprocessing.LabelBinarizer()\n",
    "\n",
    "train_emo_y = emo_bin.fit_transform(train_emo)\n",
    "tests_emo_y = emo_bin.transform(test_emo)\n",
    "# To get emotionas use emo_bin.inverse_transform(tests_emo_y)\n",
    "\n",
    "\n",
    "# MC NEW CODE\n",
    "# Convert to arrays\n",
    "# train_pol_y = np.asarray(train_pol_y)\n",
    "# test_pol_y = np.asarray(test_pol_y)\n",
    "\n",
    "# MC NEW CODE\n",
    "# Train and test x\n",
    "train_pol_x = train.ix[:, 4].tolist()\n",
    "test_pol_x = test.ix[:, 4].tolist()\n",
    "# train_pol_x\n",
    "# MC NEW CODE\n",
    "# Convert to arrays\n",
    "# train_pol_x = np.asarray(train_pol_x)\n",
    "# test_pol_x = np.asarray(test_pol_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \"\"\"Converts to lowercase, strips out punctuation,\n",
    "    removes excess whitespace within a string & leading & trailing whitespace\"\"\"\n",
    "    new_list = []\n",
    "    table = string.maketrans(\"\",\"\")\n",
    "    for elem in data:\n",
    "        elem = \"\".join(i for i in elem if ord(i)<128)\n",
    "        elem = str(elem)        \n",
    "        elem = elem.lower()\n",
    "        elem = elem.translate(table, string.punctuation)\n",
    "        \n",
    "        # Comment these 2 lines out to improve positive\n",
    "        elem = re.sub(' +',' ', elem)\n",
    "        elem = elem.strip()\n",
    "        \n",
    "        new_list.append(elem)\n",
    "    return new_list\n",
    "\n",
    "train_pol_x = process_data(train_pol_x)\n",
    "test_pol_x = process_data(test_pol_x)\n",
    "# train_pol_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 21051 \n",
      "\n",
      "Polarity counts\n",
      "0    12811\n",
      "1     8240\n",
      "Name: Positive, dtype: int64\n",
      "\n",
      "\n",
      "Avg Words 16.317277089 \n",
      "\n",
      "Emotion Counts\n",
      ":: joy         8240\n",
      ":: surprise    3849\n",
      ":: sadness     3830\n",
      ":: fear        2816\n",
      ":: anger       1555\n",
      ":: disgust      761\n",
      "Name: Emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print \"Dataset size: %s \\n\" % len(data)\n",
    "\n",
    "print \"Polarity counts\"\n",
    "print data.Positive.value_counts()\n",
    "print \"\\n\"\n",
    "#avg number of words\n",
    "\n",
    "print \"Avg Words %s \\n\" % np.mean([len(s.split(\" \")) for s in data.escape])\n",
    "print \"Emotion Counts\"\n",
    "print data.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top words\n",
    "from collections import Counter\n",
    "holder = Counter()\n",
    "\n",
    "#process entire dataset\n",
    "data_ = data.ix[:, 4].tolist()\n",
    "process_data(data_)\n",
    "\n",
    "for i in data_:\n",
    "    for word in i.split(\" \"):\n",
    "        holder[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t 17280\n",
      "the \t 8174\n",
      "to \t 7879\n",
      "I \t 7157\n",
      "a \t 5831\n",
      "and \t 5002\n",
      "my \t 4751\n",
      "of \t 4661\n",
      "in \t 3882\n",
      "is \t 3508\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "for i in holder.most_common(10):\n",
    "    #if i[0].lower() not in stopwords.words(\"english\"):\n",
    "    print \"%s \\t %s\" % (i[0],i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.84      0.81      2565\n",
      "   Positive       0.72      0.62      0.67      1646\n",
      "\n",
      "avg / total       0.75      0.76      0.75      4211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#min_df_options = [1, 2, 5, 10, 25]\n",
    "\n",
    "#for df in min_df_options:\n",
    "#print \"Minimum DF\", df\n",
    "vectorizer = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                            stop_words='english',\n",
    "                            )\n",
    "train_vectors = vectorizer.fit_transform(train_pol_x)\n",
    "test_vectors = vectorizer.transform(test_pol_x)\n",
    "\n",
    "base1 = svm.SVC(kernel='linear')\n",
    "base1.fit(train_vectors, train_pol_y)\n",
    "predict_base1 = base1.predict(test_vectors)\n",
    "\n",
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print classification_report(test_pol_y,predict_base1, target_names = target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ..., 1 0 1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCENT: ascii\n",
      "LOWERCASE OPTION: True\n",
      "Minimum DF: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.80      0.85      0.82      2598\n",
      "   Positive       0.73      0.65      0.69      1613\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n",
      "LOWERCASE OPTION: False\n",
      "Minimum DF: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.79      0.85      0.82      2598\n",
      "   Positive       0.72      0.65      0.68      1613\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://marcobonzanini.com/2015/01/19/sentiment-analysis-with-python-and-scikit-learn/\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "min_df_options = [1, 2, 5]\n",
    "strip_accents_options = ['ascii', 'unicode']\n",
    "lowercase_options = [True, False]\n",
    "\n",
    "for elem in strip_accents_options:\n",
    "    print \"ACCENT:\", elem\n",
    "    for op in lowercase_options:\n",
    "        print \"LOWERCASE OPTION:\", str(op)\n",
    "        for df in min_df_options:\n",
    "            print \"Minimum DF:\", df\n",
    "            vectorizer = TfidfVectorizer(min_df=df,\n",
    "                                         use_idf=True,\n",
    "                                        stop_words='english',\n",
    "                                         strip_accents=elem,\n",
    "                                         lowercase=op\n",
    "                                        )\n",
    "            train_vectors = vectorizer.fit_transform(train.ix[:,4].tolist())\n",
    "            test_vectors = vectorizer.transform(test.ix[:,4].tolist())\n",
    "\n",
    "            base1 = svm.SVC(kernel='linear')\n",
    "            base1.fit(train_vectors, train_pol_y)\n",
    "            predict_base1 = base1.predict(test_vectors)\n",
    "\n",
    "            target_names = [\"Negative\",\"Positive\"]\n",
    "            print classification_report(test_pol_y,predict_base1, target_names = target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.80      0.85      0.82      2598\n",
      "   Positive       0.72      0.65      0.68      1613\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                             stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train.ix[:,4].tolist())\n",
    "test_vectors = vectorizer.transform(test.ix[:,4].tolist())\n",
    "\n",
    "base1 = svm.SVC(kernel='linear')\n",
    "base1.fit(train_vectors, train_pol_y)\n",
    "predict_base1 = base1.predict(test_vectors)\n",
    "\n",
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print classification_report(test_pol_y,predict_base1, target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for C: 0.20\n",
      "F1 score for Logistic Regression: 0.763\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.86      0.82      2598\n",
      "   Positive       0.73      0.62      0.67      1613\n",
      "\n",
      "avg / total       0.76      0.77      0.76      4211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                             stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train.ix[:,4].tolist())\n",
    "test_vectors = vectorizer.transform(test.ix[:,4].tolist())\n",
    "\n",
    "base1 = svm.LinearSVC()\n",
    "\n",
    "C_options = {'C': np.arange(0.1, 1, 0.1)}\n",
    "grid = GridSearchCV(base1, C_options)\n",
    "\n",
    "grid.fit(train_vectors, train_pol_y)\n",
    "preds = grid.predict(test_vectors)\n",
    "    \n",
    "# Output best param\n",
    "print \"Best value for C: %.2f\" %grid.best_params_['C']\n",
    "print \"F1 score for Logistic Regression: %.3f\" %metrics.f1_score(test_pol_y, preds, average=\"weighted\") + \"\\n\"\n",
    "\n",
    "\n",
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print classification_report(test_pol_y, preds, target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for alpha: 0.79\n",
      "F1 score for Multinomial Naive Bayes: 0.752\n",
      "\n",
      "Best value for C: 0.70\n",
      "F1 score for Logistic Regression: 0.758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def P3(train_data, train_labels, dev_data, dev_labels):\n",
    "### STUDENT START ###\n",
    "\n",
    "    # Data setup\n",
    "    vec = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                             stop_words='english')\n",
    "    train_mat = vec.fit_transform(train_data)    \n",
    "    dev_fit = vec.transform(dev_data)\n",
    "    \n",
    "    # K-NN MODEL\n",
    "#     knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Use GridSearchCV to find optimal k value\n",
    "#     k_options = {'n_neighbors':[i for i in range(1, 3)]}\n",
    "#     knn_grid = GridSearchCV(knn, k_options)\n",
    "\n",
    "#     knn_grid.fit(train_mat, train_labels)\n",
    "#     preds = knn_grid.predict(dev_fit)\n",
    "    \n",
    "    # Output best param\n",
    "#     print \"Best value for k: %d\" %knn_grid.best_params_['n_neighbors']\n",
    "#     print \"F1 score for K-NN: %.3f\" %metrics.f1_score(dev_labels, preds, average=\"weighted\") + \"\\n\"\n",
    "    \n",
    "    # MULTINOMIAL NAIVE BAYES\n",
    "    # Repeat process for multinomial Naive Bayes\n",
    "    mul = MultinomialNB(alpha=0.5)\n",
    "    \n",
    "    alpha_options = {'alpha': np.arange(0.01, 1, 0.01)}\n",
    "    mul_grid = GridSearchCV(mul, alpha_options)\n",
    "    \n",
    "    mul_grid.fit(train_mat, train_labels)\n",
    "    mul_preds = mul_grid.predict(dev_fit)\n",
    "    \n",
    "    # Output best param\n",
    "    print \"Best value for alpha: %.2f\" %mul_grid.best_params_['alpha']\n",
    "    print \"F1 score for Multinomial Naive Bayes: %.3f\" %metrics.f1_score(dev_labels, mul_preds, average=\"weighted\") + \"\\n\"\n",
    "\n",
    "    \n",
    "    # LOGISTIC REGRESSION\n",
    "    # Repeat process for multinomial Naive Bayes\n",
    "    log = LogisticRegression()\n",
    "#     log = LogisticRegression(class_weight='balanced')\n",
    "    \n",
    "    C_options = {'C': np.arange(0.1, 1, 0.1)}\n",
    "    log_grid = GridSearchCV(log, C_options)\n",
    "\n",
    "    log_grid.fit(train_mat, train_labels)\n",
    "    log_preds = log_grid.predict(dev_fit)\n",
    "    \n",
    "    # Output best param\n",
    "    print \"Best value for C: %.2f\" %log_grid.best_params_['C']\n",
    "    print \"F1 score for Logistic Regression: %.3f\" %metrics.f1_score(dev_labels, log_preds, average=\"weighted\") + \"\\n\"\n",
    "    \n",
    "    # Output sum of squared weights for a series of values of C\n",
    "#     C_vals = np.arange(0.1, 1, 0.1)\n",
    "#     for val in C_vals:\n",
    "#         log_mod = LogisticRegression(C=val)\n",
    "#         log_mod.fit(train_mat, train_labels)\n",
    "#         print \"Sum of squared weights for C=%.2f:\" %val, np.square(log_mod.coef_).sum(axis=1)\n",
    "    \n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P3(train_pol_x, train_pol_y, test_pol_x, test_pol_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16840,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(train_pol_y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
