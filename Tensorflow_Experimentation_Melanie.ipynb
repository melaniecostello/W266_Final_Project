{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import HTMLParser as htm\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "\n",
    "# SK-learn library for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Positive</th>\n",
       "      <th>escape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138881940341260288:</td>\n",
       "      <td>I got a surprise for all you bitches...pull th...</td>\n",
       "      <td>:: surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>I got a surprise for all you bitches...pull th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144479819843911683:</td>\n",
       "      <td>If I was a thief.. The first thing I would ste...</td>\n",
       "      <td>:: joy</td>\n",
       "      <td>1</td>\n",
       "      <td>If I was a thief.. The first thing I would ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139110849120972800:</td>\n",
       "      <td>\"&amp;quot;@RevRunWisdom: not afraid of tomorrow, ...</td>\n",
       "      <td>:: fear</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"@RevRunWisdom: not afraid of tomorrow, for I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141532076791971840:</td>\n",
       "      <td>\"Extreme can neither fight nor fly.&amp;#xA;-- Wil...</td>\n",
       "      <td>:: fear</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Extreme can neither fight nor fly.\\n-- Willia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145353048817012736:</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "      <td>:: surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id                                              Tweet  \\\n",
       "0  138881940341260288:  I got a surprise for all you bitches...pull th...   \n",
       "1  144479819843911683:  If I was a thief.. The first thing I would ste...   \n",
       "2  139110849120972800:  \"&quot;@RevRunWisdom: not afraid of tomorrow, ...   \n",
       "3  141532076791971840:  \"Extreme can neither fight nor fly.&#xA;-- Wil...   \n",
       "4  145353048817012736:  Thinks that @melbahughes had a great 50th birt...   \n",
       "\n",
       "       Emotion  Positive                                             escape  \n",
       "0  :: surprise         0  I got a surprise for all you bitches...pull th...  \n",
       "1       :: joy         1  If I was a thief.. The first thing I would ste...  \n",
       "2      :: fear         0  \"\"@RevRunWisdom: not afraid of tomorrow, for I...  \n",
       "3      :: fear         0  \"Extreme can neither fight nor fly.\\n-- Willia...  \n",
       "4  :: surprise         0  Thinks that @melbahughes had a great 50th birt...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tweet_data_1.csv\",sep='\\t',quoting=3)\n",
    "data[\"escape\"] = data.apply(lambda row: htm.HTMLParser().unescape(row[1].decode(\"utf-8\")),axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and test data frames\n",
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "\n",
    "# Train and test target labels for polarity\n",
    "train_pol_y = train.ix[:,3].tolist()\n",
    "test_pol_y = test.ix[:,3].tolist()\n",
    "\n",
    "# Binarize labels for sub-emotion classifier\n",
    "train_emo = train.ix[:,2].tolist()\n",
    "test_emo = test.ix[:,2].tolist()\n",
    "emo_bin = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Labels for sub-emotion classifier\n",
    "train_emo_y = emo_bin.fit_transform(train_emo)\n",
    "tests_emo_y = emo_bin.transform(test_emo)\n",
    "\n",
    "# Train and test inputs\n",
    "train_pol_x = train.ix[:, 4].tolist()\n",
    "test_pol_x = test.ix[:, 4].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emo_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get matrix ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matrix ids for each tweet were built using GloVe word embeddings\n",
    "# Because construction of matrix ids is computationally expensive,\n",
    "# matrix ids were saved and will simply be reloaded\n",
    "d = np.load('ids.npz')\n",
    "train_ids = d['train_ids']\n",
    "test_ids = d['test_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n"
     ]
    }
   ],
   "source": [
    "# Pull in word list & vectors\n",
    "wordsList = np.load('wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('wordVectors.npy')\n",
    "print ('Loaded the word vectors!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# For Polarity Classifier\n",
    "def getTrainBatch(train_data, train_labels, train_ids):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    # iterate through batch size\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1, (len(train_data)-1))\n",
    "        if train_labels[num-1] == 1:\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "            \n",
    "        arr[i] = train_ids[num-1:num]\n",
    "        \n",
    "    return arr.astype(int), labels\n",
    "\n",
    "def getTestBatch(test_data, test_labels, test_ids):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,(len(test_data)-1))\n",
    "        \n",
    "        if test_labels[num-1] == 1:\n",
    "            labels.append([1,0])\n",
    "        else:\n",
    "            labels.append([0,1])\n",
    "            \n",
    "        arr[i] = test_ids[num-1:num]\n",
    "        \n",
    "    return arr.astype(int), labels\n",
    "\n",
    "# For sub-emotion classifier\n",
    "def getTrainBatch_subEmo(train_data, train_labels, train_ids, batchSize, maxSeqLength):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    # iterate through batch size\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1, (len(train_data)-1))\n",
    "        labels.append(train_labels[num-1])\n",
    "            \n",
    "        arr[i] = train_ids[num-1:num]\n",
    "        \n",
    "    return arr.astype(int), labels\n",
    "\n",
    "\n",
    "def getTestBatch_subEmo(test_data, test_labels, test_ids, batchSize, maxSeqLength):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,(len(test_data)-1))\n",
    "        labels.append(test_labels[num-1])\n",
    "            \n",
    "        arr[i] = test_ids[num-1:num]\n",
    "        \n",
    "    return arr.astype(int), labels\n",
    "\n",
    "def matmul3d(X, W):\n",
    "    \"\"\"Wrapper for tf.matmul to handle a 3D input tensor X.\n",
    "    Will perform multiplication along the last dimension.\n",
    "    Args:\n",
    "      X: [m,n,k]\n",
    "      W: [k,l]\n",
    "    Returns:\n",
    "      XW: [m,n,l]\n",
    "    \"\"\"\n",
    "    Xr = tf.reshape(X, [-1, tf.shape(X)[2]])\n",
    "    XWr = tf.matmul(Xr, W)\n",
    "    newshape = [tf.shape(X)[0], tf.shape(X)[1], tf.shape(W)[1]]\n",
    "    return tf.reshape(XWr, newshape)\n",
    "\n",
    "\n",
    "def MakeFancyRNNCell(H, keep_prob, num_layers=1):\n",
    "    \"\"\"Make a fancy RNN cell.\n",
    "    Use tf.nn.rnn_cell functions to construct an LSTM cell.\n",
    "    Initialize forget_bias=0.0 for better training.\n",
    "    Args:\n",
    "      H: hidden state size\n",
    "      keep_prob: dropout keep prob (same for input and output)\n",
    "      num_layers: number of cell layers\n",
    "    Returns:\n",
    "      (tf.nn.rnn_cell.RNNCell) multi-layer LSTM cell with dropout\n",
    "    \"\"\"\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(H, forget_bias=0.0)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell, input_keep_prob=keep_prob, output_keep_prob=keep_prob)\n",
    "#     cell = tf.contrib.rnn.MultiRNNCell([cell for _ in range(num_layers)])\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([cell] * num_layers)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-emotion Classifier without polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model\n",
    "\n",
    "Changes: \n",
    "- adding forget_bias to the LSTM Cell\n",
    "- adding keep_prob\n",
    "\n",
    "Check on:\n",
    "- use of tf.nn.dynamic_rnn cell vs MultiRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Layer shape (75, 34, 50)\n",
      "Output of RNN shape (75, 34, 50)\n",
      "Weights shape (50, 75)\n",
      "Bias shape (75,)\n",
      "Value x Weight shape (?, ?, ?)\n",
      "Logits shape (?, ?, 75)\n",
      "(75, 6)\n",
      "(450, 1)\n",
      "(75, 34, 50)\n",
      "Tensor(\"Reshape_1:0\", shape=(2550, 50), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 450 and 2550 for 'Training_Layer/sampled_softmax_loss/concat_4' (op: 'ConcatV2') with input shapes: [450,1], [2550,100], [] and with computed input tensors: input[2] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5ac6a559ab3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m                                                      \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                                      \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumDimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                                      num_sampled=100, num_classes=numClasses)\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mtrain_loss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_step_one_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.pyc\u001b[0m in \u001b[0;36msampled_softmax_loss\u001b[0;34m(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name)\u001b[0m\n\u001b[1;32m   1260\u001b[0m       \u001b[0mremove_accidental_hits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_accidental_hits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mpartition_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1263\u001b[0m   sampled_losses = nn_ops.softmax_cross_entropy_with_logits(labels=labels,\n\u001b[1;32m   1264\u001b[0m                                                             logits=logits)\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.pyc\u001b[0m in \u001b[0;36m_compute_sampled_logits\u001b[0;34m(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[0;31m# Construct output logits and labels. The true labels/logits start at col 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m     \u001b[0mout_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_logits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m     \u001b[0;31m# true_logits is a float tensor, ones_like(true_logits) is a float tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;31m# of ones. We then divide by num_true to ensure the per-example labels sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1032\u001b[0m   return gen_array_ops._concat_v2(values=values,\n\u001b[1;32m   1033\u001b[0m                                   \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                                   name=name)\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36m_concat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \"\"\"\n\u001b[1;32m    518\u001b[0m   result = _op_def_lib.apply_op(\"ConcatV2\", values=values, axis=axis,\n\u001b[0;32m--> 519\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    520\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 450 and 2550 for 'Training_Layer/sampled_softmax_loss/concat_4' (op: 'ConcatV2') with input shapes: [450,1], [2550,100], [] and with computed input tensors: input[2] = <1>."
     ]
    }
   ],
   "source": [
    "# Specify parameters\n",
    "maxSeqLength = max([len(elem.split()) for elem in data.ix[:, 4]]) #Maximum number of words in a tweet\n",
    "batchSize = 75\n",
    "hiddenStateSize = 1\n",
    "# lstmUnits = 2\n",
    "numClasses = 6\n",
    "numDimensions = 50\n",
    "keepProb = 0.5\n",
    "learningRate = 0.001\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "# Reset graph & create placeholders\n",
    "tf.reset_default_graph()\n",
    "labels = tf.placeholder(tf.int32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])\n",
    "\n",
    "# Lookup word vectors\n",
    "with tf.name_scope(\"Embedding_Layer\"):\n",
    "    data_vec = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "    data_vec = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "    print \"Embedding Layer shape\", data_vec.shape\n",
    "\n",
    "# Construct RNN/LSTM cell and recurrent layer.\n",
    "with tf.name_scope(\"Cell_RNN_Layer\"):\n",
    "    lstmCell = tf.contrib.rnn.BasicLSTMCell(numDimensions, forget_bias=0.0)\n",
    "    lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, input_keep_prob=keepProb, output_keep_prob=keepProb)            \n",
    "#     initial_h_ = lstmCell.zero_state(batchSize, tf.float32)\n",
    "    lstmCell = tf.contrib.rnn.MultiRNNCell([lstmCell] * hiddenStateSize)\n",
    "    value, _ = tf.nn.dynamic_rnn(lstmCell, data_vec, dtype=tf.float32)\n",
    "    print \"Output of RNN shape\", value.shape\n",
    "    \n",
    "with tf.name_scope(\"Output_Layer\"):\n",
    "    weight = tf.Variable(tf.random_uniform([numDimensions, batchSize], -1.0, 1.0))\n",
    "    print \"Weights shape\", weight.shape\n",
    "    \n",
    "    bias = tf.zeros(batchSize, tf.float32)\n",
    "    print \"Bias shape\", bias.shape\n",
    "\n",
    "    multiplier = matmul3d(value, weight)\n",
    "    print \"Value x Weight shape\", multiplier.shape\n",
    "    prediction = tf.add(multiplier, bias)\n",
    "    print \"Logits shape\", prediction.shape\n",
    "    \n",
    "    # Define correct predictions and accuracy\n",
    "    comparison = tf.argmax(prediction,1)\n",
    "    correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "    # Define loss & optimizer\n",
    "    loss_one_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=prediction)\n",
    "    loss_ = tf.reduce_mean(loss_one_)\n",
    "\n",
    "print labels.shape\n",
    "print tf.reshape(labels, [-1, 1]).shape\n",
    "print value.shape\n",
    "print tf.reshape(value, [-1, numDimensions])\n",
    "\n",
    "with tf.name_scope(\"Training_Layer\"):\n",
    "    # Loss computation (sampled, for training)\n",
    "#     loss_step_one_ = tf.nn.sampled_softmax_loss(weights=weight, biases=bias, \n",
    "#                                                      labels=tf.reshape(labels, [-1, 1]), \n",
    "#                                                      inputs=tf.reshape(value, [-1, numDimensions]), \n",
    "#                                                      num_sampled=200, num_classes=numClasses)\n",
    "\n",
    "    loss_step_one_ = tf.nn.sampled_softmax_loss(weights=tf.transpose(weight), biases=bias, \n",
    "                                                     labels=tf.reshape(labels, [-1, 1]), \n",
    "                                                     inputs=tf.reshape(value, [-1, numDimensions]), \n",
    "                                                     num_sampled=100, num_classes=numClasses)\n",
    "    train_loss_ = tf.reduce_mean(loss_step_one_)\n",
    "            \n",
    "    # Define optimizer and training op\n",
    "    train_step_ = tf.train.AdagradOptimizer(learning_rate=learningRate).minimize(train_loss_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore - Scratch paper notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Output_Layer\"):\n",
    "            \n",
    "    # W_out_ is the transpose of W_in_\n",
    "    self.W_out_ = tf.transpose(self.W_in_)\n",
    "            \n",
    "    # Initialize b_out_\n",
    "    self.b_out_ = tf.zeros(self.V, tf.float32, name=\"b_out_\")\n",
    "\n",
    "    # Logits will be of (batch size, max time, V)\n",
    "    self.logits_ = tf.add(matmul3d(self.output_, self.W_out_), self.b_out_)\n",
    "            \n",
    "            \n",
    "    # Loss computation (true loss, for prediction)\n",
    "    self.loss_one_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.target_y_, logits=self.logits_)\n",
    "    self.loss_ = tf.reduce_mean(self.loss_one_)\n",
    "    \n",
    "with tf.name_scope(\"Training_Layer\"):\n",
    "    # Loss computation (sampled, for training)\n",
    "    self.loss_step_one_ = tf.nn.sampled_softmax_loss(weights=tf.transpose(self.W_out_), biases=self.b_out_, \n",
    "                                                     labels=tf.reshape(self.target_y_, [-1, 1]), \n",
    "                                                     inputs=tf.reshape(self.output_, [-1, self.H]), \n",
    "                                                     num_sampled=self.softmax_ns, num_classes=self.V)\n",
    "    self.train_loss_ = tf.reduce_mean(self.loss_step_one_)\n",
    "            \n",
    "    # Define optimizer and training op\n",
    "    self.train_step_ = tf.train.AdagradOptimizer(learning_rate=self.learning_rate_).minimize(self.train_loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify parameters\n",
    "maxSeqLength = max([len(elem.split()) for elem in data.ix[:, 4]]) #Maximum number of words in a tweet\n",
    "batchSize = 75\n",
    "hiddenStateSize = 2\n",
    "# lstmUnits = 2\n",
    "numClasses = 6\n",
    "numDimensions = 50\n",
    "keepProb = 0.5\n",
    "learningRate = 0.001\n",
    "\n",
    "iterations = 1000\n",
    "\n",
    "# Reset graph & create placeholders\n",
    "tf.reset_default_graph()\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])\n",
    "\n",
    "# Lookup word vectors\n",
    "data_vec = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data_vec = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "# Feed RNN cell\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(hiddenStateSize, forget_bias=0.0)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, input_keep_prob=keepProb, output_keep_prob=keepProb)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data_vec, dtype=tf.float32)\n",
    "\n",
    "# Get final output\n",
    "weight = tf.Variable(tf.truncated_normal([hiddenStateSize, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "# Define correct predictions and accuracy\n",
    "comparison = tf.argmax(prediction,1)\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "# Define loss & optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss)\n",
    "# optimizer = tf.train.AdagradOptimizer(learning_rate=learningRate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be same size: logits_size=[2550,75] labels_size=[75,6]\n\t [[Node: Output_Layer/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Output_Layer/Reshape_2, Output_Layer/Reshape_3)]]\n\nCaused by op u'Output_Layer/SoftmaxCrossEntropyWithLogits', defined at:\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-910112ebba1e>\", line 52, in <module>\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1646, in softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2305, in _softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[2550,75] labels_size=[75,6]\n\t [[Node: Output_Layer/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Output_Layer/Reshape_2, Output_Layer/Reshape_3)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f90a57c64579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Next Batch of reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextBatchLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTrainBatch_subEmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pol_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_emo_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxSeqLength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnextBatchLabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Write summary to Tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must be same size: logits_size=[2550,75] labels_size=[75,6]\n\t [[Node: Output_Layer/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Output_Layer/Reshape_2, Output_Layer/Reshape_3)]]\n\nCaused by op u'Output_Layer/SoftmaxCrossEntropyWithLogits', defined at:\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-910112ebba1e>\", line 52, in <module>\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1646, in softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2305, in _softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/melanie_costello/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): logits and labels must be same size: logits_size=[2550,75] labels_size=[75,6]\n\t [[Node: Output_Layer/SoftmaxCrossEntropyWithLogits = SoftmaxCrossEntropyWithLogits[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Output_Layer/Reshape_2, Output_Layer/Reshape_3)]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch_subEmo(train_pol_x, train_emo_y, train_ids, batchSize, maxSeqLength);\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "   \n",
    "    # Write summary to Tensorboard\n",
    "    summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    writer.add_summary(summary, i)\n",
    "\n",
    "#     # Save the network every 10,000 training iterations\n",
    "#     if (i % 10000 == 0 and i != 0):\n",
    "#         save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "#         print(\"saved to %s\" % save_path)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy for this batch:', 36.000001430511475)\n",
      "('Accuracy for this batch:', 40.000000596046448)\n",
      "('Accuracy for this batch:', 42.666667699813843)\n",
      "('Accuracy for this batch:', 42.666667699813843)\n",
      "('Accuracy for this batch:', 46.666666865348816)\n",
      "('Accuracy for this batch:', 34.666666388511658)\n",
      "('Accuracy for this batch:', 30.666667222976685)\n",
      "('Accuracy for this batch:', 25.333333015441895)\n",
      "('Accuracy for this batch:', 49.333333969116211)\n",
      "('Accuracy for this batch:', 40.000000596046448)\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch_subEmo(test_pol_x, tests_emo_y, test_ids, batchSize, maxSeqLength);\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compare:', array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "# Show index of predicted class\n",
    "print(\"Compare:\", (sess.run(comparison, {input_data: nextBatch, labels: nextBatchLabels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Preds:', array([[-0.014025  ,  0.06395618,  0.12048888,  0.38174605,  0.00953795,\n",
      "         0.07971515],\n",
      "       [-0.00301381,  0.08063177,  0.21235675,  0.44487906, -0.03570636,\n",
      "         0.11071764],\n",
      "       [ 0.02004176,  0.02027215,  0.12705526,  0.25619584,  0.09074374,\n",
      "         0.15652873],\n",
      "       [ 0.01999545,  0.02020205,  0.12666899,  0.25593045,  0.09093395,\n",
      "         0.15639834],\n",
      "       [ 0.02003685,  0.02026472,  0.12701431,  0.25616771,  0.0907639 ,\n",
      "         0.1565149 ],\n",
      "       [-0.01359886,  0.06284045,  0.11891198,  0.37825832,  0.01187535,\n",
      "         0.08056186],\n",
      "       [-0.00301309,  0.08062685,  0.21234521,  0.4448629 , -0.03569534,\n",
      "         0.11071844],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [-0.00301183,  0.08061852,  0.2123259 ,  0.44483566, -0.03567678,\n",
      "         0.11071994],\n",
      "       [-0.01395453,  0.06377167,  0.1202281 ,  0.38116929,  0.0099245 ,\n",
      "         0.07985517],\n",
      "       [-0.00284813,  0.07965933,  0.2101739 ,  0.44170892, -0.03354707,\n",
      "         0.11093884],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [-0.00301404,  0.08063333,  0.21236041,  0.44488412, -0.03570983,\n",
      "         0.11071738],\n",
      "       [ 0.02004093,  0.02027089,  0.12704828,  0.25619107,  0.09074716,\n",
      "         0.15652637],\n",
      "       [ 0.02004079,  0.02027069,  0.12704717,  0.2561903 ,  0.09074771,\n",
      "         0.156526  ],\n",
      "       [-0.00301354,  0.08063003,  0.21235272,  0.44487333, -0.03570247,\n",
      "         0.11071796],\n",
      "       [ 0.01998109,  0.02018031,  0.12654918,  0.25584814,  0.09099293,\n",
      "         0.15635791],\n",
      "       [-0.01407713,  0.06409266,  0.12068176,  0.3821727 ,  0.00925204,\n",
      "         0.07961158],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.02003549,  0.02026266,  0.12700295,  0.2561599 ,  0.09076949,\n",
      "         0.15651107],\n",
      "       [-0.00300229,  0.08055129,  0.2121675 ,  0.44461527, -0.03552634,\n",
      "         0.11073045],\n",
      "       [-0.01402753,  0.0639628 ,  0.12049824,  0.3817668 ,  0.00952408,\n",
      "         0.07971013],\n",
      "       [-0.00301382,  0.08063187,  0.21235698,  0.44487935, -0.03570655,\n",
      "         0.11071762],\n",
      "       [-0.0030107 ,  0.08061092,  0.2123082 ,  0.44481078, -0.03565978,\n",
      "         0.11072127],\n",
      "       [-0.01401049,  0.06391818,  0.12043517,  0.38162726,  0.00961757,\n",
      "         0.07974399],\n",
      "       [ 0.02002085,  0.02024049,  0.12688078,  0.25607598,  0.09082966,\n",
      "         0.15646984],\n",
      "       [-0.00315416,  0.08157699,  0.21455985,  0.44797352, -0.03781743,\n",
      "         0.11055462],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.01964094,  0.01966542,  0.12371197,  0.25389868,  0.09239003,\n",
      "         0.15540026],\n",
      "       [-0.01398474,  0.06385078,  0.1203399 ,  0.38141656,  0.00975879,\n",
      "         0.07979514],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [-0.01402543,  0.0639573 ,  0.12049045,  0.38174957,  0.00953561,\n",
      "         0.0797143 ],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [-0.00301465,  0.08063775,  0.2123709 ,  0.44489866, -0.03571974,\n",
      "         0.11071673],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.02004062,  0.02027042,  0.12704572,  0.25618932,  0.09074843,\n",
      "         0.15652551],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [-0.01401897,  0.06394039,  0.12046657,  0.3816967 ,  0.00957103,\n",
      "         0.07972713],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.02004093,  0.02027089,  0.12704831,  0.25619107,  0.09074716,\n",
      "         0.15652639],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.02003781,  0.02026617,  0.12702227,  0.25617319,  0.09075998,\n",
      "         0.1565176 ],\n",
      "       [-0.01115449,  0.0564406 ,  0.10986681,  0.35825232,  0.02528284,\n",
      "         0.08541869],\n",
      "       [-0.01386525,  0.06353793,  0.11989775,  0.38043863,  0.01041418,\n",
      "         0.08003256],\n",
      "       [-0.00301411,  0.08063383,  0.2123616 ,  0.44488579, -0.03571096,\n",
      "         0.1107173 ],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [-0.00301271,  0.08062425,  0.21233916,  0.44485441, -0.03568953,\n",
      "         0.11071891],\n",
      "       [-0.00301533,  0.08067965,  0.21249029,  0.4450393 , -0.03581659,\n",
      "         0.11072341],\n",
      "       [ 0.01990128,  0.02005949,  0.12588343,  0.2553907 ,  0.09132077,\n",
      "         0.1561332 ],\n",
      "       [ 0.01772778,  0.01676941,  0.10775407,  0.24293399,  0.10024802,\n",
      "         0.15001392],\n",
      "       [-0.00299326,  0.08050834,  0.21207783,  0.44447637, -0.03543201,\n",
      "         0.11074452],\n",
      "       [-0.01402862,  0.06396564,  0.12050225,  0.38177565,  0.00951813,\n",
      "         0.07970797],\n",
      "       [-0.01402528,  0.06395691,  0.12048991,  0.38174835,  0.00953643,\n",
      "         0.0797146 ],\n",
      "       [-0.01387593,  0.06356589,  0.11993726,  0.38052601,  0.01035561,\n",
      "         0.08001134],\n",
      "       [-0.00305547,  0.08092194,  0.21303865,  0.44582993, -0.03635527,\n",
      "         0.11067116],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.0200326 ,  0.02025828,  0.12697878,  0.25614333,  0.09078139,\n",
      "         0.15650292],\n",
      "       [-0.00300581,  0.08057916,  0.21223485,  0.44470692, -0.03558895,\n",
      "         0.11072718],\n",
      "       [-0.00301291,  0.08062549,  0.21234199,  0.44485846, -0.0356923 ,\n",
      "         0.11071864],\n",
      "       [-0.01361799,  0.06289053,  0.11898275,  0.37841484,  0.01177046,\n",
      "         0.08052386],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [-0.0030141 ,  0.08063374,  0.21236137,  0.44488549, -0.03571077,\n",
      "         0.11071731],\n",
      "       [ 0.0185551 ,  0.01802174,  0.11465479,  0.24767548,  0.09684997,\n",
      "         0.15234315],\n",
      "       [ 0.02002932,  0.02025332,  0.12695149,  0.25612456,  0.09079483,\n",
      "         0.15649369],\n",
      "       [ 0.00902759,  0.0035997 ,  0.03518479,  0.19307154,  0.13598254,\n",
      "         0.12551938],\n",
      "       [ 0.01999508,  0.02020149,  0.12666589,  0.25592834,  0.09093547,\n",
      "         0.1563973 ],\n",
      "       [-0.01352322,  0.06264242,  0.11863209,  0.37763926,  0.01229023,\n",
      "         0.08071215],\n",
      "       [ 0.02002329,  0.02024419,  0.12690115,  0.25608996,  0.09081963,\n",
      "         0.15647671],\n",
      "       [-0.01353861,  0.0626827 ,  0.11868902,  0.37776515,  0.01220586,\n",
      "         0.08068159],\n",
      "       [-0.00301392,  0.08063238,  0.21235812,  0.44488102, -0.03570771,\n",
      "         0.1107175 ]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Show actual predicted values\n",
    "print(\"Preds:\", (sess.run(prediction, {input_data: nextBatch, labels: nextBatchLabels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_emo_y[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
